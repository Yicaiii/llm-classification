{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3112f557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.1+cpu\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbd9944",
   "metadata": {},
   "source": [
    "## Technical Notes: PyTorch Environment Issue on Windows\n",
    "\n",
    "During development, importing PyTorch caused the Jupyter kernel to crash on Windows\n",
    "(e.g., `torch_python.dll` loading errors and WinError 4551). This issue was not related\n",
    "to model code or the HuggingFace Trainer API, but to Windows application control policies\n",
    "blocking PyTorch native DLLs in the original Conda environment.\n",
    "\n",
    "### Solution\n",
    "To ensure stability and reproducibility, a clean CPU-only PyTorch environment was created:\n",
    "\n",
    "- A dedicated Conda environment (`llm_cpu`) with Python 3.10\n",
    "- Installation of the official CPU-only PyTorch wheels via pip\n",
    "- Explicit registration and selection of the Jupyter kernel for this environment\n",
    "\n",
    "This approach avoids GPU/CUDA dependencies, bypasses system-level DLL restrictions,\n",
    "and provides a stable setup for fine-tuning transformer models on CPU.\n",
    "\n",
    "Baseline experiments in this project were therefore conducted on CPU.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60e92aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crellamaybe\\anaconda3\\envs\\llm_cpu\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06798a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47920cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crellamaybe\\anaconda3\\envs\\llm_cpu\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "from transformers import (\n",
    "    BertTokenizer,\n",
    "    BertForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")\n",
    "\n",
    "#ä¸æå‰å¼•å…¥ accelerateï¼ˆTrainer ä¼šå¤„ç†ï¼‰ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ea565b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Prompt: Is it morally right to try to have a c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Prompt: What is the difference between marriag...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Prompt: explain function calling. how would yo...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Prompt: How can I create a test set for a very...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Prompt: What is the best way to travel from Te...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          input_text  label\n",
       "0  Prompt: Is it morally right to try to have a c...      0\n",
       "1  Prompt: What is the difference between marriag...      1\n",
       "2  Prompt: explain function calling. how would yo...      2\n",
       "3  Prompt: How can I create a test set for a very...      0\n",
       "4  Prompt: What is the best way to travel from Te...      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/processed/train_processed.csv\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55f09dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 57477 entries, 0 to 57476\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   input_text  57477 non-null  object\n",
      " 1   label       57477 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 898.2+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    20064\n",
       "1    19652\n",
       "2    17761\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info()\n",
    "df[\"label\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d3f1704",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Train / Validation Split\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    df[\"input_text\"].tolist(),\n",
    "    df[\"label\"].tolist(),\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=df[\"label\"].tolist(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0968f3bb",
   "metadata": {},
   "source": [
    "I used stratified train-validation splitting to preserve the original class distribution, especially because the dataset is imbalanced and the tie class is relatively rare. This ensures that evaluation metrics remain meaningful and comparable across experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017fd956",
   "metadata": {},
   "source": [
    "Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "446f5277",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "train_encodings = tokenizer(\n",
    "    train_texts,\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    max_length=512,\n",
    ")\n",
    "\n",
    "val_encodings = tokenizer(\n",
    "    val_texts,\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    max_length=512,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9d194d",
   "metadata": {},
   "source": [
    "Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffad7157",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cea54bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ClassificationDataset(train_encodings, train_labels)\n",
    "val_dataset = ClassificationDataset(val_encodings, val_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e2e0445",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\",\n",
    "    num_labels=3\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb66271a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=1)\n",
    "\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels, preds, average=\"weighted\"\n",
    "    )\n",
    "    acc = accuracy_score(labels, preds)\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482da7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",            \n",
    "    per_device_train_batch_size=2,      # ğŸ”¥ CPU å¿…é¡»å°\n",
    "    per_device_eval_batch_size=4,\n",
    "    eval_steps=500,\n",
    "    logging_steps=100,\n",
    "    save_strategy=\"no\",                 # ä¸å­˜ checkpointï¼ˆçœæ—¶é—´ï¼‰\n",
    "    use_cpu=True,                       # æ›¿ä»£ no_cudaï¼ˆæ–° APIï¼‰\n",
    "    fp16=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "145cd517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# ğŸ” Sanity check: use small subset\n",
    "# ================================\n",
    "SANITY_CHECK = True\n",
    "\n",
    "if SANITY_CHECK:\n",
    "    train_dataset = torch.utils.data.Subset(train_dataset, range(500))\n",
    "    val_dataset   = torch.utils.data.Subset(val_dataset, range(100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a6f01d78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39' max='750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 39/750 03:42 < 1:11:10, 0.17 it/s, Epoch 0.15/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 8\u001b[0m\n\u001b[0;32m      1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m      2\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m      3\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      6\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics,\n\u001b[0;32m      7\u001b[0m )\n\u001b[1;32m----> 8\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\crellamaybe\\anaconda3\\envs\\llm_cpu\\lib\\site-packages\\transformers\\trainer.py:2325\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   2323\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   2324\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2326\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\crellamaybe\\anaconda3\\envs\\llm_cpu\\lib\\site-packages\\transformers\\trainer.py:2674\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2667\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   2668\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[0;32m   2669\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   2670\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED\n\u001b[0;32m   2671\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[0;32m   2672\u001b[0m )\n\u001b[0;32m   2673\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[1;32m-> 2674\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2677\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   2678\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m   2679\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   2680\u001b[0m ):\n\u001b[0;32m   2681\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   2682\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[1;32mc:\\Users\\crellamaybe\\anaconda3\\envs\\llm_cpu\\lib\\site-packages\\transformers\\trainer.py:4071\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   4068\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m==\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED:\n\u001b[0;32m   4069\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscale_wrt_gas\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m-> 4071\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mbackward(loss, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   4073\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach()\n",
      "File \u001b[1;32mc:\\Users\\crellamaybe\\anaconda3\\envs\\llm_cpu\\lib\\site-packages\\accelerate\\accelerator.py:2852\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[1;34m(self, loss, **kwargs)\u001b[0m\n\u001b[0;32m   2850\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlomo_backward(loss, learning_rate)\n\u001b[0;32m   2851\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2852\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\crellamaybe\\anaconda3\\envs\\llm_cpu\\lib\\site-packages\\torch\\_tensor.py:625\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    616\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    617\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    618\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    623\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    624\u001b[0m     )\n\u001b[1;32m--> 625\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    626\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    627\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\crellamaybe\\anaconda3\\envs\\llm_cpu\\lib\\site-packages\\torch\\autograd\\__init__.py:354\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    349\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    351\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    353\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 354\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    361\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    362\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\crellamaybe\\anaconda3\\envs\\llm_cpu\\lib\\site-packages\\torch\\autograd\\graph.py:841\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    839\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    840\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 841\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    842\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    843\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    844\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    845\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f9b443",
   "metadata": {},
   "source": [
    "The full training pipeline is implemented, but due to CPU constraints I did not run full fine-tuning locally. In practice, this setup is designed for GPU-based training, while local runs focus on validating correctness and inference.\n",
    "\n",
    "ä¸­æ–‡\n",
    "\n",
    "è®­ç»ƒæµç¨‹æ˜¯å®Œæ•´å®ç°çš„ï¼Œä½†è€ƒè™‘åˆ° CPU çš„é™åˆ¶ï¼Œæˆ‘æ²¡æœ‰åœ¨æœ¬åœ°å®Œæ•´è·‘å®Œ BERT å¾®è°ƒã€‚å®é™…ä½¿ç”¨ä¸­è¿™ç±»æ¨¡å‹é€šå¸¸åœ¨ GPU æˆ–äº‘ç«¯è®­ç»ƒï¼Œæœ¬åœ°ä¸»è¦ç”¨äºéªŒè¯ pipeline å’Œæ¨ç†æµç¨‹ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f4c9d2",
   "metadata": {},
   "source": [
    "\n",
    "## ğŸ§  What Is the Trainer Training? | Trainer åœ¨è®­ç»ƒä»€ä¹ˆï¼Ÿ\n",
    "\n",
    "### ğŸ‡¬ğŸ‡§ English Explanation\n",
    "\n",
    "In this project, HuggingFaceâ€™s `Trainer` is used as a **training controller**, not as a model itself.\n",
    "\n",
    "The actual model being trained is:\n",
    "\n",
    "- **BERT encoder (`bert-base-uncased`)**\n",
    "- **A classification head on top of BERT**, producing 3 logits:\n",
    "  - Response A wins\n",
    "  - Response B wins\n",
    "  - Tie\n",
    "\n",
    "Formally, the architecture can be written as:\n",
    "\n",
    "```\n",
    "\n",
    "Input Text (Prompt + Response A + Response B)\n",
    "â†“\n",
    "Tokenizer (input_ids, attention_mask)\n",
    "â†“\n",
    "BERT Encoder (Transformer layers)\n",
    "â†“\n",
    "[CLS] representation\n",
    "â†“\n",
    "Linear Classification Head (hidden_size â†’ 3)\n",
    "â†“\n",
    "Logits: [score_A, score_B, score_Tie]\n",
    "\n",
    "```\n",
    "\n",
    "During training, the `Trainer` performs the following steps at each iteration:\n",
    "\n",
    "1. Loads a batch of tokenized inputs and labels\n",
    "2. Runs a forward pass through the model\n",
    "3. Computes the **cross-entropy loss** using the ground-truth label  \n",
    "4. Backpropagates gradients through both the BERT encoder and the classification head\n",
    "5. Updates model parameters using gradient descent\n",
    "6. Periodically evaluates performance on the validation set\n",
    "\n",
    "The optimization objective is to maximize the probability assigned to the human-preferred response.\n",
    "\n",
    "This means the model learns **implicit human preference patterns**, such as:\n",
    "- relevance to the prompt  \n",
    "- coherence and correctness  \n",
    "- helpfulness and clarity  \n",
    "- stylistic appropriateness  \n",
    "\n",
    "Conceptually, this model acts as a **supervised preference model**, which corresponds to the reward modeling stage commonly used in **RLHF (Reinforcement Learning from Human Feedback)** pipelines.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ‡¨ğŸ‡³ ä¸­æ–‡è§£é‡Š\n",
    "\n",
    "åœ¨æœ¬é¡¹ç›®ä¸­ï¼ŒHuggingFace çš„ `Trainer` å¹¶ä¸æ˜¯æ¨¡å‹æœ¬èº«ï¼Œè€Œæ˜¯ä¸€ä¸ª**è®­ç»ƒæµç¨‹æ§åˆ¶å™¨**ã€‚\n",
    "\n",
    "çœŸæ­£è¢«è®­ç»ƒçš„æ¨¡å‹ç”±ä¸¤éƒ¨åˆ†ç»„æˆï¼š\n",
    "\n",
    "- **BERT ç¼–ç å™¨ï¼ˆbert-base-uncasedï¼‰**\n",
    "- **BERT é¡¶éƒ¨çš„åˆ†ç±»å¤´ï¼ˆ3 åˆ†ç±»ï¼‰**ï¼Œåˆ†åˆ«è¡¨ç¤ºï¼š\n",
    "  - å›ç­” A æ›´å—åå¥½\n",
    "  - å›ç­” B æ›´å—åå¥½\n",
    "  - ä¸¤è€…æ‰“å¹³ï¼ˆtieï¼‰\n",
    "\n",
    "æ¨¡å‹ç»“æ„å¯ä»¥æ¦‚æ‹¬ä¸ºï¼š\n",
    "\n",
    "```\n",
    "\n",
    "è¾“å…¥æ–‡æœ¬ï¼ˆPrompt + Response A + Response Bï¼‰\n",
    "â†“\n",
    "åˆ†è¯å™¨ï¼ˆTokenizerï¼‰\n",
    "â†“\n",
    "BERT ç¼–ç å™¨ï¼ˆå¤šå±‚ Transformerï¼‰\n",
    "â†“\n",
    "[CLS] å‘é‡è¡¨ç¤º\n",
    "â†“\n",
    "çº¿æ€§åˆ†ç±»å±‚ï¼ˆè¾“å‡º 3 ä¸ª logitï¼‰\n",
    "\n",
    "```\n",
    "\n",
    "åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œ`Trainer` åœ¨æ¯ä¸€ä¸ª step ä¸­ä¼šæ‰§è¡Œï¼š\n",
    "\n",
    "1. è¯»å–ä¸€ä¸ª batch çš„è¾“å…¥æ–‡æœ¬å’Œå¯¹åº”æ ‡ç­¾  \n",
    "2. è¿›è¡Œå‰å‘ä¼ æ’­ï¼Œè®¡ç®—æ¨¡å‹è¾“å‡º  \n",
    "3. ä½¿ç”¨ **äº¤å‰ç†µæŸå¤±ï¼ˆCross-Entropy Lossï¼‰** è®¡ç®—é¢„æµ‹ä¸çœŸå®æ ‡ç­¾ä¹‹é—´çš„å·®è·  \n",
    "4. åå‘ä¼ æ’­æ¢¯åº¦ï¼Œæ›´æ–° BERT ç¼–ç å™¨å’Œåˆ†ç±»å¤´çš„å‚æ•°  \n",
    "5. æŒ‰è®¾å®šçš„æ­¥æ•°åœ¨éªŒè¯é›†ä¸Šè¿›è¡Œè¯„ä¼°  \n",
    "\n",
    "è®­ç»ƒçš„ç›®æ ‡æ˜¯ï¼š  \n",
    "**è®©æ¨¡å‹ç»™â€œäººç±»æ›´åå¥½çš„å›ç­”â€åˆ†é…æ›´é«˜çš„æ¦‚ç‡ã€‚**\n",
    "\n",
    "å› æ­¤ï¼Œæ¨¡å‹å®é™…ä¸Šå­¦ä¹ çš„æ˜¯ä¸€ç§**äººç±»åå¥½å‡½æ•°**ï¼Œä¾‹å¦‚ï¼š\n",
    "- å›ç­”æ˜¯å¦åˆ‡é¢˜  \n",
    "- æ˜¯å¦é€»è¾‘æ¸…æ™°ã€ä¿¡æ¯å……åˆ†  \n",
    "- è¡¨è¾¾æ˜¯å¦è‡ªç„¶ã€æœ‰å¸®åŠ©  \n",
    "\n",
    "ä»æ–¹æ³•è®ºä¸Šçœ‹ï¼Œè¿™ä¸€æ¨¡å‹å¯ä»¥è§†ä¸º **RLHFï¼ˆåŸºäºäººç±»åé¦ˆçš„å¼ºåŒ–å­¦ä¹ ï¼‰æµç¨‹ä¸­çš„ç›‘ç£å¼åå¥½æ¨¡å‹ï¼ˆpreference / reward modelï¼‰é˜¶æ®µ**ï¼Œè€Œä¸æ˜¯ç®€å•çš„æ–‡æœ¬åˆ†ç±»ä»»åŠ¡ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”‘ Key Takeaway | æ ¸å¿ƒæ€»ç»“\n",
    "\n",
    "- The `Trainer` optimizes **both the language representation (BERT) and the decision layer**.\n",
    "- The task is **preference learning**, not ordinary classification.\n",
    "- This setup mirrors real-world **human feedback modeling** used in modern LLM alignment pipelines.\n",
    "\n",
    "```\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0291270b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
